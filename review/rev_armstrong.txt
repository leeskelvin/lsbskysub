This is a nice, thourough paper with a good comparison of different methods of background estimation.  Well done!

I have a few comments/questions that I have ordered by section

Introduction

"This algorithm passes the transpose of the spatially varying point spread function (PSF) as a kernel over the image" - Unless the software has changed recently, I don't think it actually uses the transpose of the PSF.  It uses a circular Gaussian approximation to the PSF.  Oh, I see that you describe this in 4.5.1.  These two descriptions should match.

Section 2.1 

I think it would be easier to interpret your galaxies density numbers if you use objects / arcmin^2. I think this is fairly standard in most areas of astronomy.  

I don’t know if the rainbow color map is the best for astronomical images as it can introduce artificial structure in data and sometimes hide structure.  Is there a reason not to use a gray scale color map?

Section 2.2 

You should not expect the psf to be easily modeled on the HSC coadded data? The problem comes from discontinuities at the CCD boundaries. How high an order did you use for the polynomial fit in psfex? Even with a high order, a polynomial it may have trouble if there are discontinuities. I don’t know how much it matters for your analysis, but I have seen it produce fairly large residuals in some regions of the image.  You do include some residual images, but those can be hard to interpret sometimes.

Section 3.2 

Does sextractor give you a PSF deconvolved value of the size?  It seems like this would be a better fit than using the straight half lite radii. Since the high density region has a smaller PSF don’t you want your modeling to match that sample? From Figure 6, it seems like the model is closer to the larger seeing low density data


It is clear that CLASS_STAR does not fully isolate the galaxy sample.  Are these removed somehow when you try to model the sample?

Why did you use +- 25% around your fit? This doesn't seem to capture the variance in the data.


Section 3.4 

The ellipticity become larger for fainter sources.  I am guessing this is from the noise in the measurement and not from the intrinsic distribution. Have you tried to account for the difference between these factors when modeling your faint galaxies?

Section 3.5 

Why does the super pixel images look so noisy?  Maybe it is related to the smoothing scale that you used?

Section 3.9

I don't think you need to include table 1, a description of what it contains in the text is sufficient.

Looking at the yaml file you feed to galsim you use an interpolated image as the psf, but don't use the draw option 'no_pixel'.  Without this you will apply the pixel convolution twice.

For the psf, do you use a represntative psf with galsim, or do you use the full psf model?

Section 4.1

How did you arrive at the given power law to extend objects?  How sensitive is this approach if you change the amount of masking?

Section 4.2

Can you reliably fit a sersic profile to galaxies at faint magnitude?  We had some problems doing this with HSC.  As stated in the text this will mostly affect bright sources, maybe you can focus on these objects.

Section 4.3.1

"check images for the segmentation map (BACKGROUND)" should this be SEGMENTATION?

Section 4.3.2

"There is a long an inglorious history" -> long and inglorious

My understanding is that sextractor does not do deblending?  It only assigns different pixels to different objects and does not try to separate the flux from a single pixel into different components.

Section 4.3.4

"subtracting our mult-Sersic model image" also "the fitted PSF-convolved multi-Sersic model" - I thought your model was a single Sersic per galaxy?


Section 4.4.3

The segmentation map looks strange for the bright sources.  Is this typical for the Gnuastro processing?

Section 4.4.4

"The impact of modelled masks significantly aids the background estimator". - is this really true?  It seems to have a small effect

Section 4.5.2

"In the LSST PIPELINES d6 configurations" - what is d6? I guess you mean P6

Your simulations don't include correlated noise from the warping process.  I think this is the dominant source of correlated noise in the HSC data even more than the convolution with the PSF.


Section 5

I assume that the background is 0 in your simulations. I don’t think that is explicitly stated anywhere.

Is a mean and standard deviation the right metric here.  It seems like you could get those right but have spatial variation across the image.  Do you have a way to test that for your different methods? I see that you partially address this later on.

Your reported impact of field density on the background level is 0.9 +- 0.8.  This does not seem statistically significant.  Looking at individual cases, it seems the all sources version is much more impacted than the simulations with just bright galaxies.  Is the significance reduced by the lower impact from the bright sims?

"The impact of source profile is moderate" - The quoted size is close to the field density number, why do say it is only moderate?  

Did you consider doing a modification to the LSST pipeline where you increase how much footprints are grown in the detection stage?  This might be able to mimic the other modifications you made with the other packages.  It wouldn't be magnitude dependent but would likely improve things.

Without having a lot of background in LSB galaxies, how significant is a 0.5 mag improvement in the sky estimation? It would be nice if you could connect this to a specific science application. Maybe this is beyond the scope of this paper?

"Such an obvious trend is likely testament" -> a testament

How do you measure the luminosity for the sources when you compare to the truth?  Are you using cmodel for LSST, mag_auto for SExtractor? Presumably, different algorithms will perform better.  I'm trying to understand the performance of the LSST results.  Previous studies I've seen have not shown a large bias.  What is the trend you see with magnitude?

Conclusion

It seems a bit long to me with too much detail.  I think it would be improved if you could more succinctly highlight the main results of your paper without going through all the results one by one.

Appendix C

I don't think you need two figures to demonstrate that galsim does better than Sextractor.
