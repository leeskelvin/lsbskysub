    This is a nice, thorough paper with a good comparison of different methods
    of background estimation.  Well done!

LSK: Thank you, and thank you for taking the time to carefully review this
study, very much appreciated!

    I have a few comments/questions that I have ordered by section

    Introduction

    "This algorithm passes the transpose of the spatially varying point spread
    function (PSF) as a kernel over the image" - Unless the software has changed
    recently, I don't think it actually uses the transpose of the PSF.  It uses
    a circular Gaussian approximation to the PSF.  Oh, I see that you describe
    this in 4.5.1. These two descriptions should match.

LSK: Thank you, we have modified this section to read: "This algorithm first
identifies high signal-to-noise stars on the stellar locus, using these to
model the spatially varying PSF over the entire image and subsequently
facilitating characterisation of simply connected regions above a given
detection threshold as detections (see Section 4.5.1 for further details)."

    Section 2.1

    I think it would be easier to interpret your galaxies density numbers if you
    use objects / arcmin^2. I think this is fairly standard in most areas of
    astronomy.

LSK: We've modified Figure 1 and also all the relevant references in the text.
We did not modify Figure 5 however, as this format allows us to more easily
compare to the Ji et al. 2018 paper efforts which directly led to this study.

    I don’t know if the rainbow color map is the best for astronomical images as
    it can introduce artificial structure in data and sometimes hide structure.
    Is there a reason not to use a gray scale color map?

LSK: Thank you, this is a very fair point. Most rainbow style colour maps have
been removed and replaced with grey scale. The remaining colours and colour maps
used throughout the rest of the paper have been chosen to be colour-blind
friendly, black/white print friendly and screen capture friendly.

    Section 2.2

    You should not expect the psf to be easily modeled on the HSC coadded data?
    The problem comes from discontinuities at the CCD boundaries. How high an
    order did you use for the polynomial fit in psfex? Even with a high order, a
    polynomial it may have trouble if there are discontinuities. I don’t know
    how much it matters for your analysis, but I have seen it produce fairly
    large residuals in some regions of the image.  You do include some residual
    images, but those can be hard to interpret sometimes.

LSK: We used a PSFVAR_DEGREES polynomial order of 2 to estimate our PSF
(i.e., the default PSFEx value - this information has also been added into
the text, thank you for raising this). We agree that modelling the PSF from the
coadded data may not always be desirable, however, in this instance we only
require an approximate PSF in order to generate output PSF-convolved simulated
imaging. In that sense, our simulated images should be reasonably comparable
to our input HSC-type imaging, and so we think that this is acceptable for us to
do here.

    Section 3.2

    Does sextractor give you a PSF deconvolved value of the size?  It seems like
    this would be a better fit than using the straight half lite radii.

LSK: Sadly, SExtractor does not give a deconvolved value of size. We could
potentially calculate one, but I'm not sure it's required here. We only need an
estimate of size to help guide our resultant simulated image construction. As a
consequence, I don't think it would modify our simulated images too much if we
were to implement this, certainly not for the largest of objects, and not too
much for the smallest simulated objects either (we have a hard half-light radius
lower-limit of 1 pixel).

    Since the high density region has a smaller PSF don’t you want your modeling
    to match that sample? From Figure 6, it seems like the model is closer to
    the larger seeing low density data

LSK: If anything, a larger PSF may actually be desirable here, as it contributes
to scattering more light away from the core regions of sources and out into a
contaminated background model, which is what we are trying to test against.
However, as noted above, the only purpose of these plots is to approximately
mimic a true HSC dataset in order to generate a set of HSC-style simulated
imaging, so even this approximate measure of the half-light radius trend is good
enough for our purposes.

    It is clear that CLASS_STAR does not fully isolate the galaxy sample. Are
    these removed somehow when you try to model the sample?

LSK: Yes, you are correct that CLASS_STAR does not fully remove all point-source
type objects, but we do not think this is a major issue here. As shown in the
figures throughout Section 3, we're aiming to generate overall trends which we
subsequently use to define our simulated input catalogues. As the remaining
point-sources do not dominate the number density in any particular regime, and
our simulated imaging does not contain point sources, then we believe our
simulated images are robust against any bias here. Furthermore, the brightest
end (brighter than M_r ~ 22 mag) are entirely simulated in any case, throwing
away any detections from SExtractor (which are more likely to be impacted by
point sources), and instead using our best-fit log-linear trend line to assign
objects in the bright regime.

    Why did you use +- 25% around your fit? This doesn't seem to capture the
    variance in the data.

LSK: Thank you for your feedback here. We didn't want to stray too far
away from +-25 percent so that we're not being too overly impacted by extreme
or edge-case values, hence our choice to limit to this range. As we mentioned
above, this trend line serves only to generate a semi-realistic input which we
can subsequently use to generate simulated imaging.

    Section 3.3

    The ellipticity becomes larger for fainter sources.  I am guessing this is
    from the noise in the measurement and not from the intrinsic distribution.
    Have you tried to account for the difference between these factors when
    modeling your faint galaxies?

LSK: Somewhat, yes. As shown in Figure 7, our faintest simulated sources (bottom
panel) are more circular than those that have been derived from real data (top
panel). We exclude sources fainter than m_r=27 mag (i.e., 6 further 0.5 mag bins
all the way down to m_r=30 mag) and instead use the model derived from the
bright-end sources to assign faint source ellipticities. In this way, we're
using the true ellipticity distribution from brighter magnitude ranges to help
derive a model which gives a prediction for the ellipticity at the faintest
magnitudes in our simulated imaging. With that said, the faintest sources are
increasingly likely to be irregular (e.g., Binggeli, Sandage & Tammann, 1988),
and so one might want to recover a slightly higher ellipticity in this faint
regime. We hope that the compromise we have here is sufficient.

    Section 3.5

    Why does the super pixel images look so noisy?  Maybe it is related to the
    smoothing scale that you used?

LSK: For Figure 8, this is the result of a standard 100x100 pixel binning
procedure. This figure is now in grey-scale as noted above, and we hope it now
looks as you might expect.

    Section 3.9

    I don't think you need to include table 1, a description of what it contains
    in the text is sufficient.

LSK: A very fair point. Rather than remove this, we've moved it into the
Appendix next to the GalSim config file, for reference.

    Looking at the yaml file you feed to galsim you use an interpolated image as
    the psf, but don't use the draw option 'no_pixel'.  Without this you will
    apply the pixel convolution twice.

LSK: Thank you for this comment, as this was not a feature of GalSim we were
previously aware of. We've spent some time thinking about this comment, and
fully agree with you as to its use. We hadn't accounted for the fact that
'no_pixel' may have had an impact on our image simulation. As a test, we've
re-generated our simulated imaging with this option turned on. I attach a figure
to this reply ('no_pixel_test.png') showing the impact of turning on or off this
option for one of our given simulated fields. This figure shows the original
data (top left), the new data with no_pixel turned on (top right) and the
difference between these two (new minus old, bottom row). All panels except for
the lower right are asinh scaled to the central 90% flux value range. The lower
right panel is linearly scaled to the median plus/minus 1-sigma. Images are
smoothed with a Gaussian of FWHM=10 pixels. As you can see, the impact of
turning on this flag is fortunately relatively small. Unfortunately, the
initialisation seed is not the same between the 'off' and 'on' outputs,
resulting in the random background noise being different in both outputs. As a
result, in addition to the differing noise realisations, we do note five small
bright spots in the very centre of the five brightest sources in this field (two
in the upper left corner, and three in the lower right corner). As the areas
impacted by this modification are small, and in any case, we ultimately end up
masking these pixels for our subsequent sky estimation routines (the centres of
all detected sources are masked out) then we hope that you agree with us that we
should be okay to continue using the original data as we currently have it
described in the paper. If you do have any further concerns on this issue
however, please do let us know, and we can discuss it further.

    For the psf, do you use a represntative psf with galsim, or do you use the
    full psf model?

LSK: we use the PSFEx-derived PSF as described in Section 2.2.

    Section 4.1

    How did you arrive at the given power law to extend objects?  How sensitive
    is this approach if you change the amount of masking?

LSK: this value was chosen based on prior testing on our input data, and also to
somewhat mimic the methodology already established in Ji et al. 2018, allowing
for a direct comparison here. The original idea in Ji et al. 2018 was to
sufficiently mask enough of the obviously extended flux leaking out into the
background map without removing too much area so that nothing is left to
determine a background model. We aimed to replicate that here. As this is a
power law, minor modifications can have a significant impact on the brightest of
objects, as you might suspect. Nevertheless, we think that the solution we
present in equation 2 is sufficiently aggressive to cover much of this flux
leakage without being overly aggressive in removing too many pixels.

    Section 4.2

    Can you reliably fit a sersic profile to galaxies at faint magnitude?  We
    had some problems doing this with HSC.  As stated in the text this will
    mostly affect bright sources, maybe you can focus on these objects.

LSK: Yes, we agree that modelling the faintest sources can be tricky. For this
reason, we only model sources brighter than m_r = 25 mag (a more complete
description is provided in the second paragraph of Section 4.2). I hope you
agree that this lower limit is sufficient as we do, precisely for the reasons
you describe.

    Section 4.3.1

    "check images for the segmentation map (BACKGROUND)" should this be
    SEGMENTATION?

LSK: yes, thank you!

    Section 4.3.2

    "There is a long an inglorious history" -> long and inglorious

LSK: thank you!

    My understanding is that sextractor does not do deblending?  It only assigns
    different pixels to different objects and does not try to separate the flux
    from a single pixel into different components.

LSK: Yes, you are correct that SExtractor does not partition flux within one
pixel into multiple objects, instead assigning different pixels to different
objects. This procedure is termed 'deblending' in the SExtractor manual and
config files (hence our usage of it here), however, we agree that others may not
prefer this term. To that end, we've now swapped out the word 'deblend' for
'segment' wherever appropriate, which we hope is a more appropriate and less
ambiguous term to use.

    Section 4.3.4

    "subtracting our mult-Sersic model image" also "the fitted PSF-convolved
    multi-Sersic model" - I thought your model was a single Sersic per galaxy?

LSK: it's multi-Sersic in the sense that there are multiple simulated galaxies
in each frame, but yes, each simulated galaxy is only modelled with a single
Sersic component. We'd be happy to change this to something else if you think it
appropriate however.

    Section 4.4.3

    The segmentation map looks strange for the bright sources.  Is this typical
    for the Gnuastro processing?

LSK: Strange in what sense? Gnuastro is bottom-up, starting with noise
everywhere and chiseling out sources. As a consequence, it can leave a lot of
ragged edges that those who are familiar with SExtractor (like me!) are not
so used to. What this results in (and what we end up finding) is that the
Gnuastro fluxes for the brightest of sources can ultimately unfortunately
end up being erroneously over-estimated.

    Section 4.4.4

    "The impact of modelled masks significantly aids the background estimator".
    - is this really true?  It seems to have a small effect

LSK: Only in the sense that the modelled mask has removed much of the remnant
bright source contamination in the upper right corner of each panel in Figure
16. We agree that use of the word 'significant' may be a stretch here! We have
reworded this sentence thus: "The impact of modelled masks appears to somewhat
aid the background estimator in producing an unbiased background map."

    Section 4.5.2

    "In the LSST PIPELINES d6 configurations" - what is d6? I guess you mean P6

LSK: yes, thank you.

    Your simulations don't include correlated noise from the warping process.  I
    think this is the dominant source of correlated noise in the HSC data even
    more than the convolution with the PSF.

LSK: The noise correlation that we'd have to be concerned by here are
noise correlations in the EBL - this is purely a root N process, and the
warping has no effect on that. We're not sensitive to sky noise.

    Section 5

    I assume that the background is 0 in your simulations. I don’t think that is
    explicitly stated anywhere.

LSK: Yes, that is correct. We do write in Section 3.10 "These simulated images
are background subtracted (i.e., Poisson noise oscillates about a level of zero
counts)", however, we can and should clarify this, thank you. We've added
explicit mention if this in the opening paragraph of Section 3.10, and also
again in Appendix C.

    Is a mean and standard deviation the right metric here.  It seems like you
    could get those right but have spatial variation across the image.  Do you
    have a way to test that for your different methods? I see that you partially
    address this later on.

LSK: (is this referring to Table 3? - now Table 2, following the removal of
Table 1 above) Yes, higher-orders and other measures of spatial variation are
important too, however, there is already a lot of information to take away in
this study and this table, and we were wary of over-complicating our analyses
too much. We would however happily consider another metric that might easily be
substituted into this table, if possible.

    Your reported impact of field density on the background level is 0.9 +- 0.8.
    This does not seem statistically significant.  Looking at individual cases,
    it seems the all sources version is much more impacted than the simulations
    with just bright galaxies.  Is the significance reduced by the lower impact
    from the bright sims?

LSK: Thank you for this comment. Following this feedback, we have significantly
re-written the results section to better encapsulate our key results. The
results section 5 is now split into three sections: trends by data type flavour
(field population, source density and source type); trends by software
configuration mode; and trends in the output results catalogues. We fully agree
with your comment that the quoted background level in the original text did not
fully capture the range of results shown here. As we are presenting quite a lot
of results in this study, we now instead provide the full range of output values
in the text and convert these to significance sigma levels. We hope that a
conversion into a significance should more easily allow the reader to gauge the
impact of each test result presented here.

    "The impact of source profile is moderate" - The quoted size is close to the
    field density number, why do say it is only moderate?

LSK: Thank you again for this comment. In line with the above reply, this
section has now been significantly restructured to better present our main
conclusions.

    Did you consider doing a modification to the LSST pipeline where you
    increase how much footprints are grown in the detection stage?  This might
    be able to mimic the other modifications you made with the other packages.
    It wouldn't be magnitude dependent but would likely improve things.

LSK: At the time of writing, we didn't have direct access to the LSST pipeline
(this began as an external project, before I joined Rubin Obs). We also wanted
to test what others already using the pipeline would find, and so haven't
made any attempt to modify the pipeline at this time. However, we are hopeful
that future efforts to improve sky estimation and source extraction in the stack
can jump off from these results going forwards.

    Without having a lot of background in LSB galaxies, how significant is a
    0.5 mag improvement in the sky estimation? It would be nice if you could
    connect this to a specific science application. Maybe this is beyond the
    scope of this paper?

LSK: In the introduction we highlight three key LSB regimes at which a 0.5 mag
improvement to sky estimation routines would make a big difference (dwarf galaxy
identification, stellar halo measurements, and intracluster light
characterisation). This is an important point however, and we should additionaly
raise this in our conclusion section also.

    "Such an obvious trend is likely testament" -> a testament

LSK: Thank you.

    How do you measure the luminosity for the sources when you compare to the
    truth? Are you using cmodel for LSST, mag_auto for SExtractor? Presumably,
    different algorithms will perform better.  I'm trying to understand the
    performance of the LSST results.  Previous studies I've seen have not shown
    a large bias.  What is the trend you see with magnitude?

LSK: Thank you for raising this, as this is important information that needs to
be in the text. We use FLUX_AUTO to derive our estimate of SExtractor magnitude,
BRIGHTNESS for Gnuastro, and base_SdssShape_instFlux for LSST (equivalent to
slot_Shape_instFlux). This information has been added into the opening paragraph
of Section 5.0.3. The catalogue I have access to for these data doesn't have
cmodel outputs included unfortunately, but it does have slot_ModelFlux_instFlux,
which is very close (<1%) to the aforementioned shape flux measures.

    Conclusion

    It seems a bit long to me with too much detail.  I think it would be
    improved if you could more succinctly highlight the main results of your
    paper without going through all the results one by one.

LSK: We fully agree with this comment, thank you. As a consequence, we have
completely re-written the conclusions section to highlight only the main results
of our study. We hope that this reads better in its now current form.

    Appendix C

    I don't think you need two figures to demonstrate that galsim does better
    than Sextractor.

LSK: thank you, we have removed the second of these figures as you suggest.

LSK: Thank you again for all your efforts in reading through the paper and
providing such detailed comments. It has been incredibly useful, and much
appreciated.